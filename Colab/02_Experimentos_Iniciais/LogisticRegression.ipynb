{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFG3eABHl7X"
      },
      "source": [
        "### Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUN0w5fRjw3N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report, RocCurveDisplay, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_d4klcBJp8c"
      },
      "source": [
        "### Carregar Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CeXXdgXMfqG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "output_path = '/content/drive/MyDrive/PS-Ligia_Time16/'\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzsmspmOhRLs"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Se você executou o notebook de EDA deste projeto, e portanto, gerou e salvou os\n",
        "datasets processados; Descomente este código abaixo e fique a vontade para\n",
        "utilizar os datasets que foram salvos no seu próprio Google Drive.\n",
        "\n",
        "Caso não tenha criado os datasets, utilize o trecho descomentado para carregar\n",
        "ele já pronto do nosso Drive.\n",
        "'''\n",
        "# df_completo = pd.read_csv(os.path.join(output_path, 'risco_cardiovascular_features.csv'))\n",
        "\n",
        "df_completo = pd.read_csv(\"https://drive.google.com/uc?id=142P-9xy-kRboRVpHj2t9OniS0DUF0QTp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qQ74wUtOkMg"
      },
      "outputs": [],
      "source": [
        "coluna_alvo = 'BP_Category'\n",
        "\n",
        "# Carrega todas as features e o alvo diretamente do arquivo de features\n",
        "print(\"\\n=== Informações do DataSet ===\")\n",
        "print(f\"Shape df_completo: {df_completo.shape}\")\n",
        "print(\"\\nValores nulos em df_completo:\")\n",
        "print(df_completo.isnull().sum())\n",
        "print(\"\\nTipos de dados:\")\n",
        "print(df_completo.dtypes)\n",
        "display(df_completo.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_pQbCi9KpXt"
      },
      "source": [
        "### Pré-Processamento dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI60IkOpJ53s"
      },
      "outputs": [],
      "source": [
        "print(\"Colunas finais (após carregamento): \", df_completo.columns.tolist())\n",
        "\n",
        "colunas_categoricas = df_completo.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(\"\\nColunas categóricas antes da codificação:\", colunas_categoricas)\n",
        "\n",
        "# Aplicar LabelEncoder a todas as colunas categóricas identificadas\n",
        "for coluna in colunas_categoricas:\n",
        "    le = LabelEncoder()\n",
        "    df_completo[coluna] = le.fit_transform(df_completo[coluna])\n",
        "    print(f\"Coluna '{coluna}' codificada.\")\n",
        "\n",
        "print(\"\\nApós codificação:\")\n",
        "print(df_completo.dtypes)\n",
        "display(df_completo.head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrTTN34lLF6m"
      },
      "source": [
        "### Divisão de Dados e Normalização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c2ngwKYK5I_"
      },
      "outputs": [],
      "source": [
        "# Separar x (features) e y (target)\n",
        "x = df_completo.drop(coluna_alvo, axis=1)\n",
        "y = df_completo[coluna_alvo] # Agora y será uma única Series com valores numéricos\n",
        "\n",
        "# Dividir treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "print(f\"\\n Dados prontos para treinar\")\n",
        "print(f\"x_train shape: {x_train_scaled.shape}\")\n",
        "print(f\"x_test shape: {x_test_scaled.shape}\")\n",
        "\n",
        "# Treinar o modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIHdWL7HLNHX"
      },
      "source": [
        "### Definição de Hiperparâmetros para GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK4UQk2KLMLh"
      },
      "outputs": [],
      "source": [
        "parametros = {\n",
        "    'C': [0.01, 1, 10, 100],\n",
        "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'penalty': ['l2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=5000),\n",
        "    parametros,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "#resultados do grid\n",
        "print(\"=\"*60)\n",
        "print(f\"✅ Melhores parâmetros: {grid_search.best_params_}\")\n",
        "print(f\"✅ Melhor acurácia no CV: {grid_search.best_score_:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2JHQ0y3LlRp"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyTmhftoLkxv"
      },
      "outputs": [],
      "source": [
        "modelo = grid_search.best_estimator_\n",
        "y_pred = modelo.predict(x_test_scaled)\n",
        "\n",
        "print(\"\\nAcurácia:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "nomes_classes = ['Elevada', 'Normal', 'Hipertensão']\n",
        "print(\"\\nRelatório:\")\n",
        "print(classification_report(y_test, y_pred, target_names=nomes_classes))\n",
        "\n",
        "# Matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
