{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TATYbUm5dwpH"
      },
      "source": [
        "### Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "svwr9VYVOPd-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Importações de ML\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import ( f1_score, accuracy_score, fbeta_score, make_scorer, precision_score, recall_score, roc_auc_score,\n",
        "    confusion_matrix, brier_score_loss)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Importações de Reamostragem\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu429sOaeGn3"
      },
      "source": [
        "### Carregar Datasets e Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8jgR_xsveAjK"
      },
      "outputs": [],
      "source": [
        "output_path = \"../../Models\"\n",
        "\n",
        "datasets = {\n",
        "    \"Base\": pd.read_csv('../../Data/risco_cardiovascular_base.csv'),\n",
        "    \"Features\": pd.read_csv('../../Data/risco_cardiovascular_features.csv')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWzeawpBeKNc"
      },
      "source": [
        "### Definição de Modelos e Hiperparâmetros para GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bSXr-wWSeNcV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Aqui criamos o grid de todos modelos com seus respectivos hiperparametros que\n",
        "vão ser combinados no gridsearch para acharmos a melhor configuração.\n",
        "\n",
        "Com a pipeline do imblearn tambem é possivel adicionar resampler ou qualquer\n",
        "pré-processamento pro grid\n",
        "\n",
        "'''\n",
        "resampler = [\n",
        "    SMOTE(random_state=42),\n",
        "    RandomOverSampler(random_state=42),\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    'passthrough'\n",
        "]\n",
        "\n",
        "models_config = {\n",
        "    'RandomForest': {\n",
        "        'model': RandomForestClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__n_estimators': [50, 100, 200],\n",
        "            'classifier__max_depth': [None, 5, 10],\n",
        "            'classifier__min_samples_split': [2, 5]\n",
        "        }\n",
        "    },\n",
        "    'DecisionTree': {\n",
        "        'model': DecisionTreeClassifier(random_state=42),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__max_depth': [None, 3, 5, 10],\n",
        "            'classifier__criterion': ['gini', 'entropy'],\n",
        "            'classifier__min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    },\n",
        "    'KNN': {\n",
        "        'model': KNeighborsClassifier(),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__n_neighbors': [3, 5, 7, 9],\n",
        "            'classifier__weights': ['uniform', 'distance'],\n",
        "            'classifier__metric': ['euclidean', 'manhattan']\n",
        "        }\n",
        "    },\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__C': [0.1, 1.0, 10.0],\n",
        "            'classifier__solver': ['lbfgs']\n",
        "        }\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model': XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__n_estimators': [50, 100],\n",
        "            'classifier__learning_rate': [0.01, 0.1],\n",
        "            'classifier__max_depth': [None, 3, 5]\n",
        "        }\n",
        "    },\n",
        "    'SVM': {\n",
        "        'model': SVC(random_state=42, probability=True),\n",
        "        'params': {\n",
        "            'resampler': resampler,\n",
        "            'classifier__C': [0.1, 1, 10],\n",
        "            'classifier__kernel': ['linear', 'rbf'],\n",
        "            'classifier__gamma': ['scale', 'auto']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chFHTsieeney"
      },
      "source": [
        "### Loop de Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFRRdGO-emIL",
        "outputId": "6f6a38ff-9ca7-4e32-8bac-781d6b346ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            ">>> Processando Dataset: Base\n",
            "\n",
            "--- Iniciando GridSearch para RandomForest ---\n",
            "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1368/1683850692.py:18: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
            "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
            "  cat_cols = X.copy().drop('BMI Category', axis=1).select_dtypes(include=['object']).columns.tolist()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Modelo e métricas de RandomForest salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para DecisionTree ---\n",
            "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
            "--- Modelo e métricas de DecisionTree salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para KNN ---\n",
            "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
            "--- Modelo e métricas de KNN salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para LogisticRegression ---\n",
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "--- Modelo e métricas de LogisticRegression salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para XGBoost ---\n",
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
            "--- Modelo e métricas de XGBoost salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para SVM ---\n",
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
            "--- Modelo e métricas de SVM salvos! ---\n",
            "\n",
            ">>> Processando Dataset: Features\n",
            "\n",
            "--- Iniciando GridSearch para RandomForest ---\n",
            "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1368/1683850692.py:18: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
            "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
            "  cat_cols = X.copy().drop('BMI Category', axis=1).select_dtypes(include=['object']).columns.tolist()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Modelo e métricas de RandomForest salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para DecisionTree ---\n",
            "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
            "--- Modelo e métricas de DecisionTree salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para KNN ---\n",
            "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n",
            "--- Modelo e métricas de KNN salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para LogisticRegression ---\n",
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "--- Modelo e métricas de LogisticRegression salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para XGBoost ---\n",
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
            "--- Modelo e métricas de XGBoost salvos! ---\n",
            "\n",
            "--- Iniciando GridSearch para SVM ---\n",
            "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n",
            "--- Modelo e métricas de SVM salvos! ---\n"
          ]
        }
      ],
      "source": [
        "results_list = []\n",
        "\n",
        "f2_scorer = make_scorer(fbeta_score, beta=2, average='macro', pos_label=None)\n",
        "\n",
        "for ds_name, df in datasets.items():\n",
        "    print(f\"\\n>>> Processando Dataset: {ds_name}\")\n",
        "\n",
        "    # Separar X e y\n",
        "    X = df.drop('BP_Category', axis=1)\n",
        "    y = df['BP_Category']\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "    bmi_order = [\"Underweight\", \"Normal Weight\", \"Overweight\", \"Obese\"]\n",
        "\n",
        "    # Identificar colunas\n",
        "    cat_cols = X.copy().drop('BMI Category', axis=1).select_dtypes(include=['object']).columns.tolist()\n",
        "    num_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "    # Preprocessor\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', StandardScaler(), num_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
        "        (\"ordinal\", OrdinalEncoder(categories=[bmi_order]), ['BMI Category']),\n",
        "    ])\n",
        "\n",
        "    # Split Treino/Teste (80/20)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    for model_name, config in models_config.items():\n",
        "\n",
        "        model_filename = f\"{model_name}_{ds_name}.pkl\"\n",
        "        metrics_filename = f\"{model_name}_{ds_name}_metrics.csv\"\n",
        "        \n",
        "        model_save_path = os.path.join(output_path, model_name)\n",
        "        metrics_save_path = os.path.join(model_save_path, 'Metrics')\n",
        "        plot_save_path = os.path.join(model_save_path, 'Plots')\n",
        "        os.makedirs(model_save_path, exist_ok=True)\n",
        "        os.makedirs(metrics_save_path, exist_ok=True)\n",
        "        os.makedirs(plot_save_path, exist_ok=True)\n",
        "        \n",
        "        full_model_path = os.path.join(model_save_path, model_filename)\n",
        "        full_metrics_path = os.path.join(metrics_save_path, metrics_filename)\n",
        "\n",
        "        # --- Verificar se modelo ja foi treinado ---\n",
        "        if os.path.exists(full_model_path) and os.path.exists(full_metrics_path):\n",
        "            print(f\"--- Modelo {model_name} já existe para Dataset {ds_name}. Carregando Resultados e Pulando treinamento... ---\")\n",
        "            saved_metrics = pd.read_csv(full_metrics_path)\n",
        "            results_list.append(saved_metrics.to_dict(orient='records')[0])\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- Iniciando GridSearch para {model_name} ---\")\n",
        "\n",
        "        # Pipeline base com placeholder para o resampler\n",
        "        pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('resampler', SMOTE()), # Placeholder que será substituído pelo Grid\n",
        "            ('classifier', config['model'])\n",
        "        ])\n",
        "\n",
        "        # Cross-Validation (10 Folds para dataset pequeno)\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "        # Grid Search\n",
        "        grid = GridSearchCV(\n",
        "            pipeline,\n",
        "            config['params'],\n",
        "            cv=cv,\n",
        "            scoring={'f2_macro': f2_scorer, 'f1_macro': 'f1_macro', 'accuracy': 'accuracy'},\n",
        "            refit='f2_macro',\n",
        "            return_train_score=True,\n",
        "            n_jobs=-1,\n",
        "            verbose=1,\n",
        "            error_score='raise'\n",
        "        )\n",
        "\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        cv_res = pd.DataFrame(grid.cv_results_)\n",
        "\n",
        "        # Métricas de Treino (do melhor modelo)\n",
        "        best_idx = grid.best_index_\n",
        "        train_f2 = cv_res.loc[best_idx, 'mean_train_f2_macro']\n",
        "        train_f1 = cv_res.loc[best_idx, 'mean_train_f1_macro']\n",
        "        train_acc = cv_res.loc[best_idx, 'mean_train_accuracy']\n",
        "\n",
        "        # Métricas de Teste\n",
        "        y_pred = grid.predict(X_test)\n",
        "        y_proba = grid.predict_proba(X_test) # Necessário para AUC e Calibração\n",
        "        test_f2 = fbeta_score(y_test, y_pred, beta=2, average='macro')\n",
        "        test_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        test_acc = accuracy_score(y_test, y_pred)\n",
        "        test_precision = precision_score(y_test, y_pred, average='macro')\n",
        "        test_recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "        # AUC-ROC\n",
        "        test_auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "        # Métrica de Calibração (Brier Score)\n",
        "        # Como Brier é binário, calculamos a média para todas as classes (macro)\n",
        "        brier_scores = []\n",
        "        for i in range(len(le.classes_)):\n",
        "            y_true_bin = (y_test == i).astype(int)\n",
        "            brier_scores.append(brier_score_loss(y_true_bin, y_proba[:, i]))\n",
        "        test_brier = np.mean(brier_scores)\n",
        "\n",
        "        # --- Matriz de Confusão (Visualização e Salvamento)---\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "        plt.title(f'Matriz de Confusão: {model_name} - {ds_name}')\n",
        "        plt.ylabel('Real')\n",
        "        plt.xlabel('Predito')\n",
        "\n",
        "        # Salva a imagem da matriz\n",
        "        plot_filename = f\"matriz_{model_name}_{ds_name}.png\"\n",
        "        plt.savefig(os.path.join(plot_save_path, plot_filename))\n",
        "        plt.close() # Fecha a figura para não sobrecarregar a memória\n",
        "\n",
        "        # ------------------------------------------------------\n",
        "\n",
        "        current_results = {\n",
        "            'Model': model_name,\n",
        "            'Dataset': ds_name,\n",
        "            'Best_Params': str(grid.best_params_),\n",
        "            'Train_F2_Macro': train_f2,\n",
        "            'Train_F1_Macro': train_f1,\n",
        "            'Train_Accuracy': train_acc,\n",
        "            'Test_F2_Macro': test_f2,\n",
        "            'Test_F1_Macro': test_f1,\n",
        "            'Test_Accuracy': test_acc,\n",
        "            'Test_Precision': test_precision,\n",
        "            'Test_Recall': test_recall,\n",
        "            'Test_AUC_ROC': test_auc,\n",
        "            'Test_Brier_Score': test_brier\n",
        "        }\n",
        "\n",
        "        # Salvar Modelo e Métricas no Drive\n",
        "        joblib.dump(grid.best_estimator_, full_model_path)\n",
        "        pd.DataFrame([current_results]).to_csv(full_metrics_path, index=False)\n",
        "\n",
        "        # No results_list.append, adicione:\n",
        "        results_list.append(current_results)\n",
        "        print(f\"--- Modelo e métricas de {model_name} salvos! ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqblz9rge-0k"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "rJJe1OJSex0F",
        "outputId": "bbac04c8-80a0-4250-9e3e-3c5c6cde0149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: RandomForest ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Base</td>\n",
              "      <td>0.998442</td>\n",
              "      <td>0.998141</td>\n",
              "      <td>0.954724</td>\n",
              "      <td>0.946667</td>\n",
              "      <td>0.944127</td>\n",
              "      <td>0.959596</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>{'classifier__max_depth': 5, 'classifier__min_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Features</td>\n",
              "      <td>0.996262</td>\n",
              "      <td>0.995539</td>\n",
              "      <td>0.954724</td>\n",
              "      <td>0.946667</td>\n",
              "      <td>0.944127</td>\n",
              "      <td>0.959596</td>\n",
              "      <td>0.997894</td>\n",
              "      <td>0.026294</td>\n",
              "      <td>{'classifier__max_depth': 5, 'classifier__min_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "0      Base        0.998442        0.998141       0.954724       0.946667   \n",
              "6  Features        0.996262        0.995539       0.954724       0.946667   \n",
              "\n",
              "   Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "0        0.944127     0.959596      1.000000          0.029197   \n",
              "6        0.944127     0.959596      0.997894          0.026294   \n",
              "\n",
              "                                         Best_Params  \n",
              "0  {'classifier__max_depth': 5, 'classifier__min_...  \n",
              "6  {'classifier__max_depth': 5, 'classifier__min_...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: DecisionTree ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Base</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.961699</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.964646</td>\n",
              "      <td>0.973232</td>\n",
              "      <td>0.026667</td>\n",
              "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Features</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973102</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.974747</td>\n",
              "      <td>0.981313</td>\n",
              "      <td>0.017778</td>\n",
              "      <td>{'classifier__criterion': 'entropy', 'classifi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "1      Base             1.0             1.0       0.961699       0.960000   \n",
              "7  Features             1.0             1.0       0.973102       0.973333   \n",
              "\n",
              "   Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "1        0.956522     0.964646      0.973232          0.026667   \n",
              "7        0.969697     0.974747      0.981313          0.017778   \n",
              "\n",
              "                                         Best_Params  \n",
              "1  {'classifier__criterion': 'entropy', 'classifi...  \n",
              "7  {'classifier__criterion': 'entropy', 'classifi...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: KNN ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Base</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.966459</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.018384</td>\n",
              "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Features</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.955178</td>\n",
              "      <td>0.946667</td>\n",
              "      <td>0.948718</td>\n",
              "      <td>0.959596</td>\n",
              "      <td>0.982271</td>\n",
              "      <td>0.024002</td>\n",
              "      <td>{'classifier__metric': 'manhattan', 'classifie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "2      Base             1.0             1.0       0.966459       0.960000   \n",
              "8  Features             1.0             1.0       0.955178       0.946667   \n",
              "\n",
              "   Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "2        0.960000     0.969697      1.000000          0.018384   \n",
              "8        0.948718     0.959596      0.982271          0.024002   \n",
              "\n",
              "                                         Best_Params  \n",
              "2  {'classifier__metric': 'manhattan', 'classifie...  \n",
              "8  {'classifier__metric': 'manhattan', 'classifie...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: LogisticRegression ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Base</td>\n",
              "      <td>0.992042</td>\n",
              "      <td>0.990708</td>\n",
              "      <td>0.915777</td>\n",
              "      <td>0.906667</td>\n",
              "      <td>0.911905</td>\n",
              "      <td>0.922727</td>\n",
              "      <td>0.995922</td>\n",
              "      <td>0.039546</td>\n",
              "      <td>{'classifier__C': 10.0, 'classifier__solver': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Features</td>\n",
              "      <td>0.997197</td>\n",
              "      <td>0.996654</td>\n",
              "      <td>0.938913</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.942929</td>\n",
              "      <td>0.997323</td>\n",
              "      <td>0.033105</td>\n",
              "      <td>{'classifier__C': 10.0, 'classifier__solver': ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "3      Base        0.992042        0.990708       0.915777       0.906667   \n",
              "9  Features        0.997197        0.996654       0.938913       0.933333   \n",
              "\n",
              "   Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "3        0.911905     0.922727      0.995922          0.039546   \n",
              "9        0.938272     0.942929      0.997323          0.033105   \n",
              "\n",
              "                                         Best_Params  \n",
              "3  {'classifier__C': 10.0, 'classifier__solver': ...  \n",
              "9  {'classifier__C': 10.0, 'classifier__solver': ...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: XGBoost ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Base</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.977337</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.969634</td>\n",
              "      <td>0.979798</td>\n",
              "      <td>0.999759</td>\n",
              "      <td>0.013998</td>\n",
              "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Features</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.977337</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.969634</td>\n",
              "      <td>0.979798</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014276</td>\n",
              "      <td>{'classifier__learning_rate': 0.1, 'classifier...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "4       Base             1.0             1.0       0.977337       0.973333   \n",
              "10  Features             1.0             1.0       0.977337       0.973333   \n",
              "\n",
              "    Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "4         0.969634     0.979798      0.999759          0.013998   \n",
              "10        0.969634     0.979798      1.000000          0.014276   \n",
              "\n",
              "                                          Best_Params  \n",
              "4   {'classifier__learning_rate': 0.1, 'classifier...  \n",
              "10  {'classifier__learning_rate': 0.1, 'classifier...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Tabela Final: SVM ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Train_F2_Macro</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_F2_Macro</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Test_Precision</th>\n",
              "      <th>Test_Recall</th>\n",
              "      <th>Test_AUC_ROC</th>\n",
              "      <th>Test_Brier_Score</th>\n",
              "      <th>Best_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Base</td>\n",
              "      <td>0.997509</td>\n",
              "      <td>0.997026</td>\n",
              "      <td>0.988867</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007127</td>\n",
              "      <td>{'classifier__C': 10, 'classifier__gamma': 'au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Features</td>\n",
              "      <td>0.993084</td>\n",
              "      <td>0.991824</td>\n",
              "      <td>0.927624</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.932828</td>\n",
              "      <td>0.991233</td>\n",
              "      <td>0.031431</td>\n",
              "      <td>{'classifier__C': 1, 'classifier__gamma': 'sca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Dataset  Train_F2_Macro  Train_Accuracy  Test_F2_Macro  Test_Accuracy  \\\n",
              "5       Base        0.997509        0.997026       0.988867       0.986667   \n",
              "11  Features        0.993084        0.991824       0.927624       0.920000   \n",
              "\n",
              "    Test_Precision  Test_Recall  Test_AUC_ROC  Test_Brier_Score  \\\n",
              "5         0.985507     0.989899      1.000000          0.007127   \n",
              "11        0.928571     0.932828      0.991233          0.031431   \n",
              "\n",
              "                                          Best_Params  \n",
              "5   {'classifier__C': 10, 'classifier__gamma': 'au...  \n",
              "11  {'classifier__C': 1, 'classifier__gamma': 'sca...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processo concluído! Os arquivos foram salvos em: ../../Models\n"
          ]
        }
      ],
      "source": [
        "df_results = pd.DataFrame(results_list)\n",
        "\n",
        "# Criar tabelas separadas por modelo\n",
        "for model_name in models_config.keys():\n",
        "    df_model = df_results[df_results['Model'] == model_name].copy()\n",
        "\n",
        "    print(f\"\\n--- Tabela Final: {model_name} ---\")\n",
        "    display(df_model[['Dataset', 'Train_F2_Macro', 'Train_Accuracy', 'Test_F2_Macro', 'Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_AUC_ROC', 'Test_Brier_Score', 'Best_Params']])\n",
        "\n",
        "print(f\"\\nProcesso concluído! Os arquivos foram salvos em: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUNszd0a6V6H"
      },
      "source": [
        "### Matrizes de Confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s1JP6eVx6D7_",
        "outputId": "2691638c-3232-4df2-82df-d166d190de91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nenhuma matriz de confusão encontrada na pasta de plots.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "from IPython.display import Image, display, HTML\n",
        "\n",
        "# 1. Caminho onde as matrizes foram salvas\n",
        "plot_save_path = os.path.join(output_path, 'plots')\n",
        "\n",
        "# 2. Buscar todas as imagens que começam com 'matriz'\n",
        "lista_matrizes = sorted(glob.glob(os.path.join(plot_save_path, \"matriz_*.png\")))\n",
        "\n",
        "if not lista_matrizes:\n",
        "    print(\"Nenhuma matriz de confusão encontrada na pasta de plots.\")\n",
        "else:\n",
        "    print(f\"Encontradas {len(lista_matrizes)} matrizes. Exibindo resultados:\\n\")\n",
        "\n",
        "    for caminho_img in lista_matrizes:\n",
        "        # Extrair o nome do modelo/dataset do nome do arquivo para o título\n",
        "        nome_arquivo = os.path.basename(caminho_img).replace('matriz_', '').replace('.png', '')\n",
        "\n",
        "        display(HTML(f\"<h3>Modelo: {nome_arquivo}</h3>\"))\n",
        "        display(Image(filename=caminho_img))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5BBklvrgb0i"
      },
      "source": [
        "### Feature Importance (Exclusivo do RandomForest e DecisionTree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1gG5WpOXWkzf",
        "outputId": "95253614-8145-43df-e51c-a222b982d2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Modelo RandomForest_Base.pkl não encontrado no caminho especificado.\n",
            "⚠️ Modelo DecisionTree_Base.pkl não encontrado no caminho especificado.\n",
            "⚠️ Modelo KNN_Base.pkl não encontrado no caminho especificado.\n",
            "⚠️ Modelo LogisticRegression_Base.pkl não encontrado no caminho especificado.\n",
            "⚠️ Modelo XGBoost_Base.pkl não encontrado no caminho especificado.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'SVC' object has no attribute 'feature_importances_'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[32m     73\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ Modelo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl não encontrado no caminho especificado.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Execução automática\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[43mgerar_graficos_importancia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mgerar_graficos_importancia\u001b[39m\u001b[34m(results_list, model_save_path, output_path)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 2. Extrair importâncias do classificador (RF ou DT)\u001b[39;00m\n\u001b[32m     34\u001b[39m classifier = pipeline.named_steps[\u001b[33m'\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m importances = \u001b[43mclassifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 3. Criar DataFrame para organizar o Top 10\u001b[39;00m\n\u001b[32m     38\u001b[39m df_imp = pd.DataFrame({\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m'\u001b[39m: feature_names,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mImportance\u001b[39m\u001b[33m'\u001b[39m: importances\n\u001b[32m     41\u001b[39m }).sort_values(by=\u001b[33m'\u001b[39m\u001b[33mImportance\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).head(\u001b[32m10\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'SVC' object has no attribute 'feature_importances_'"
          ]
        }
      ],
      "source": [
        "# --- Célula: Visualização da Importância das Features ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "def gerar_graficos_importancia(results_list, model_save_path, output_path):\n",
        "    \"\"\"\n",
        "    Carrega os modelos salvos e gera gráficos de importância das features\n",
        "    para cada combinação de Modelo e Dataset.\n",
        "    \"\"\"\n",
        "    # Configuração visual\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    for res in results_list:\n",
        "        model_name = res['Model']\n",
        "        ds_name = res['Dataset']\n",
        "\n",
        "        # Caminho do modelo salvo no Drive\n",
        "        path_modelo = os.path.join(model_save_path, f\"{model_name}_{ds_name}.pkl\")\n",
        "\n",
        "        if os.path.exists(path_modelo):\n",
        "            # Carregar o pipeline completo (inclui preprocessor e classifier)\n",
        "            pipeline = joblib.load(path_modelo)\n",
        "\n",
        "            # 1. Recuperar nomes das colunas (considerando o One-Hot Encoding)\n",
        "            # O get_feature_names_out() extrai os nomes gerados pelo ColumnTransformer\n",
        "            preprocessor = pipeline.named_steps['preprocessor']\n",
        "            feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "            # Limpar nomes (remover prefixos técnicos 'num__' e 'cat__')\n",
        "            feature_names = [name.split('__')[-1] for name in feature_names]\n",
        "\n",
        "            # 2. Extrair importâncias do classificador (RF ou DT)\n",
        "            classifier = pipeline.named_steps['classifier']\n",
        "            importances = classifier.feature_importances_\n",
        "\n",
        "            # 3. Criar DataFrame para organizar o Top 10\n",
        "            df_imp = pd.DataFrame({\n",
        "                'Feature': feature_names,\n",
        "                'Importance': importances\n",
        "            }).sort_values(by='Importance', ascending=False).head(10)\n",
        "\n",
        "            # 4. Criação do Gráfico\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            cores = 'viridis' if model_name == 'RandomForest' else 'magma'\n",
        "\n",
        "            ax = sns.barplot(\n",
        "                data=df_imp,\n",
        "                x='Importance',\n",
        "                y='Feature',\n",
        "                palette=cores,\n",
        "                hue='Feature',\n",
        "                legend=False\n",
        "            )\n",
        "\n",
        "            # Estilização\n",
        "            plt.title(f\"Top 10 Features: {model_name}\\nDataset: {ds_name}\", fontsize=14, fontweight='bold', pad=15)\n",
        "            plt.xlabel(\"Importância Relativa (Gini Importance)\", fontsize=12)\n",
        "            plt.ylabel(\"Atributos\", fontsize=12)\n",
        "\n",
        "            # Adicionar os valores numéricos nas pontas das barras para precisão\n",
        "            for i in ax.containers:\n",
        "                ax.bar_label(i, fmt='%.3f', padding=5)\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Salvar o gráfico no Drive\n",
        "            nome_arquivo = f\"feat_imp_{model_name}_{ds_name}.png\"\n",
        "            plt.savefig(os.path.join(output_path, nome_arquivo), dpi=300)\n",
        "            plt.show()\n",
        "            print(f\"✅ Gráfico de importância para {model_name} ({ds_name}) salvo com sucesso.\")\n",
        "        else:\n",
        "            print(f\"⚠️ Modelo {model_name}_{ds_name}.pkl não encontrado no caminho especificado.\")\n",
        "\n",
        "# Execução automática\n",
        "gerar_graficos_importancia(results_list, model_save_path, output_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
