{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUOKfCkN8QqY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Modelos e Validação\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler, LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (\n",
        "    fbeta_score, make_scorer, \n",
        "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, \n",
        "    accuracy_score, precision_score, recall_score\n",
        ")\n",
        "\n",
        "# Reamostragem (Oversampling/Undersampling)\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U05qKZUlGDhS"
      },
      "source": [
        "### Carregar Datasets e Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpVsJpgAO-H4"
      },
      "outputs": [],
      "source": [
        "output_path = \"../../Model/XGBoost_Models\"\n",
        "\n",
        "datasets = {\n",
        "    \"Base\": pd.read_csv('../../Data/risco_cardiovascular_base.csv'),\n",
        "    \"Features\": pd.read_csv('../../Data/risco_cardiovascular_features.csv')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Métrica Customizada\n",
        "\n",
        "Para este problema, definimos o **F2-Score** como Métrica de Rankeamento.\n",
        "\n",
        "$$F_2 = (1 + 2^2) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(2^2 \\cdot \\text{precision}) + \\text{recall}}$$\n",
        "\n",
        "- O peso $\\beta=2$ faz com que o modelo busque identificar o máximo de pacientes em risco (alto Recall), mesmo que isso gere alguns alarmes falsos adicionais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOJ75sXkb64D"
      },
      "outputs": [],
      "source": [
        "f2_scorer = make_scorer(fbeta_score, beta=2, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definição de Hiperparâmetros para GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKkcPOZwXzZi"
      },
      "outputs": [],
      "source": [
        "resampler = [\n",
        "    SMOTE(random_state=42),\n",
        "    RandomOverSampler(random_state=42),\n",
        "    RandomUnderSampler(random_state=42),\n",
        "    'passthrough'\n",
        "]\n",
        "\n",
        "model_config = {\n",
        "  'XGBoost': {\n",
        "    'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "    'params': {\n",
        "        'resampler': resampler,\n",
        "        'pca__n_components': [0.95, None],\n",
        "        'classifier__max_depth': [3, 5],\n",
        "        'classifier__learning_rate': [0.01, 0.1]\n",
        "    }\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7v8FeHEZ3q5"
      },
      "source": [
        "## Loop de Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O pré-processamento é automatizado via *ColumnTransformer*:\n",
        "\n",
        "- Ordinal Encoding: Aplicado à categoria de IMC (BMI), preservando a hierarquia natural.\n",
        "- Standard Scaling: Normalização de variáveis numéricas.\n",
        "- One-Hot Encoding: Transformação de variáveis categóricas nominais.\n",
        "\n",
        "Para cada dataset (**Base** e **Features**), o `GridSearchCV` avaliará as seguintes combinações:\n",
        "\n",
        "1.  **Balanceamento de Dados:** Comparação entre `SMOTE`, `RandomOverSampler`, `RandomUnderSampler` e a permanência dos dados originais (`passthrough`).\n",
        "\n",
        "2.  **Redução de Dimensionalidade:** Avaliação do impacto do `PCA` (mantendo 95% da variância) versus o uso de todas as colunas originais (`None`).\n",
        "3.  **Otimização do XGBoost:** Ajuste simultâneo de profundidade e taxa de aprendizado.\n",
        "\n",
        "> Isso nos permite identificar se o ganho de performance vem da engenharia de atributos, do tratamento estatístico do desbalanceamento ou da arquitetura do algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym_EQCDZZ6lT",
        "outputId": "81cfb8cb-df1b-4cf6-e0c3-6bc9afd32681"
      },
      "outputs": [],
      "source": [
        "model_save_path = output_path\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "results_list = []\n",
        "\n",
        "for ds_name, df in datasets.items():\n",
        "    print(f\"\\n>>> Processando Dataset: {ds_name}\")\n",
        "    df_clean = df.copy()\n",
        "  \n",
        "    # Preparação Features e Target\n",
        "    X = df_clean.drop('BP_Category', axis=1)\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(df_clean['BP_Category'])\n",
        "\n",
        "    # Encoding das Features\n",
        "    bmi_order = [\"Underweight\", \"Normal Weight\", \"Overweight\", \"Obese\"]\n",
        "    bmi_col = [\"BMI Category\"]\n",
        "\n",
        "    cat_cols = [c for c in X.select_dtypes(include=['object']).columns if c != \"BMI Category\"]\n",
        "    num_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('ordinal', OrdinalEncoder(categories=[bmi_order]), bmi_col),\n",
        "        ('numeric', StandardScaler(), num_cols),\n",
        "        ('categories', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "    ])\n",
        "\n",
        "    # Divisão treino/teste com estratificação\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    for model_name, config in model_config.items():\n",
        "      print(f\"\\n--- Iniciando GridSearch para {model_name} ---\")\n",
        "\n",
        "      # Imblearn para garantir que o SMOTE ocorra apenas no conjunto de treino\n",
        "      pipeline = ImbPipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('resampler', SMOTE()),\n",
        "        ('pca', PCA()),\n",
        "        ('classifier', config['model'])\n",
        "      ])\n",
        "\n",
        "      cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "      grid = GridSearchCV(\n",
        "          pipeline,\n",
        "          config['params'],\n",
        "          cv=cv,\n",
        "          scoring={'f2': f2_scorer, 'accuracy': 'accuracy'},\n",
        "          refit='f2', # O melhor modelo será escolhido pelo F2-Score\n",
        "          n_jobs=-1\n",
        "      )\n",
        "\n",
        "      grid.fit(X_train, y_train)\n",
        "\n",
        "      # Predições de Teste\n",
        "      y_pred = grid.predict(X_test)\n",
        "      y_proba = grid.predict_proba(X_test)\n",
        "\n",
        "      # Métricas de Desempenho\n",
        "      metrics = {\n",
        "        'Model': model_name,\n",
        "        'Dataset': ds_name,\n",
        "        'Best_Params': grid.best_params_,\n",
        "        'PCA_Used': grid.best_params_.get('pca__n_components') is not None,\n",
        "        'SMOTE_Used': not isinstance(grid.best_params_.get('resampler'), str),\n",
        "\n",
        "        'Train_CV_F2': grid.best_score_,\n",
        "        'Test_F2': fbeta_score(y_test, y_pred, beta=2, average='macro'),\n",
        "        'Overfitting_Gap': grid.best_score_ - fbeta_score(y_test, y_pred, beta=2, average='macro'),\n",
        "\n",
        "        'Test_Recall': recall_score(y_test, y_pred, average='macro'),\n",
        "        'Test_Precision': precision_score(y_test, y_pred, average='macro'),\n",
        "        'Test_Acc': accuracy_score(y_test, y_pred),\n",
        "        'Test_AUC': roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
        "      }\n",
        "\n",
        "      results_list.append(metrics)\n",
        "\n",
        "      joblib.dump(grid.best_estimator_, os.path.join(model_save_path, f\"{model_name}_{ds_name}.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2l0P9zHoyV"
      },
      "source": [
        "### Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "mMnRd1J2YdtK",
        "outputId": "0a155453-3c8b-4ac1-82f4-b548f9530222"
      },
      "outputs": [],
      "source": [
        "# Melhor resultado para cada Dataset (Ordenado pelo F2-Score)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "metrics_save_path = os.path.join(output_path, \"Metrics\")\n",
        "os.makedirs(metrics_save_path, exist_ok=True)\n",
        "\n",
        "df_results = pd.DataFrame(results_list)\n",
        "df_results = df_results.sort_values(by='Test_F2', ascending=False)\n",
        "\n",
        "print(\"\\n--- COMPARATIVO DE PERFORMANCE ---\")\n",
        "\n",
        "for model_name in model_config.keys():\n",
        "    df_model = df_results[df_results[\"Model\"] == model_name].copy()\n",
        "\n",
        "    filename = f\"resultado_final_{model_name}.csv\"\n",
        "    df_model.to_csv(os.path.join(metrics_save_path, filename), index=False)\n",
        "    \n",
        "    print(f\"\\n--- Tabela Final: {model_name} ---\")\n",
        "    display(df_model[\n",
        "        ['Dataset', 'Train_CV_F2', 'Test_F2', 'Overfitting_Gap', 'Test_Recall', 'Test_Precision', 'Test_AUC', 'PCA_Used', 'SMOTE_Used']\n",
        "    ])\n",
        "\n",
        "print(f\"\\nProcesso concluído! Os arquivos foram salvos em: {metrics_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Coil1CfSqZbG",
        "outputId": "2bdecc9e-70ea-4602-a80c-264f2a305f91"
      },
      "outputs": [],
      "source": [
        "# Matriz de Confusão (Visualização da precisão e recall do modelo)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "for i, res in enumerate(results_list[:2]): # Pega os melhores de cada dataset\n",
        "    model = joblib.load(os.path.join(model_save_path, f\"{res['Model']}_{res['Dataset']}.pkl\"))\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
        "    disp.plot(ax=axes[i], cmap='Blues', colorbar=False)\n",
        "    axes[i].set_title(f\"Matriz: {res['Model']} - {res['Dataset']}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blfdsVYPtfCH"
      },
      "source": [
        "### Visualização de *Feature Importance*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O gráfico abaixo utiliza o critério de Ganho (Gain) do XGBoost. O Ganho mede a melhoria relativa na precisão trazida por uma característica ao criar os ramos da árvore. Variáveis com maior ganho são as que mais contribuem para a diferenciação dos níveis de pressão arterial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R6IC377cuhA6",
        "outputId": "5ebf5768-314a-48bc-96fb-708e82990d24"
      },
      "outputs": [],
      "source": [
        "# 1. Identificar o melhor modelo de cada dataset baseado no Test_F2\n",
        "best_per_ds = pd.DataFrame(results_list).sort_values('Test_F2', ascending=False).drop_duplicates('Dataset')\n",
        "\n",
        "for index, row in best_per_ds.iterrows():\n",
        "    # Carregar o modelo salvo\n",
        "    model_path = os.path.join(model_save_path, f\"{row['Model']}_{row['Dataset']}.pkl\")\n",
        "    pipeline = joblib.load(model_path)\n",
        "\n",
        "    # Extrair o nome do dataset e das features\n",
        "    xgb_model = pipeline.named_steps['classifier']\n",
        "    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "    # Extrair a importância nativa (Ganho/Gain)\n",
        "    importances = xgb_model.feature_importances_\n",
        "    df_imp = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "    df_imp = df_imp.sort_values(by='Importance', ascending=True) # Todas as features\n",
        "\n",
        "    plt.figure(figsize=(10, 0.4 * len(df_imp)))\n",
        "    plt.barh(df_imp['Feature'], df_imp['Importance'], color='teal')\n",
        "    plt.title(f\"Importância de Todas as Variáveis: {row['Model']} - {row['Dataset']}\\n(F2-Score: {row['Test_F2']:.4f})\")\n",
        "    plt.xlabel(\"Importância Relativa (Ganho)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
